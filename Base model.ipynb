{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-carter",
   "metadata": {},
   "source": [
    "**Until now** In our previous folder **(Data Cleaning and visualization)**<br>\n",
    "1:-We found that **(150,150) is the best image size for our image**.<br>\n",
    "2:-We remove corrupted images.<br>\n",
    "3:-Split our data into train and validation<br>\n",
    "4:-Balanced our Imbalanced training dataset with the help of **Image Data Augmentation.**\n",
    "\n",
    "In this folder **(Base model)** work we doing.<br>\n",
    "\n",
    "1:- Generate our data by using **ImageDataGenerator**.<br>\n",
    "2:- Resacle and resize our data in **ImagedataGenerator**.<br>\n",
    "3:- Built our **Model Base**.<br>\n",
    "\n",
    "And other process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir('cats-v-dogs/training/cats/')))\n",
    "print(len(os.listdir('cats-v-dogs/training/dogs/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"cats-v-dogs/training/\"\n",
    "validation = \"cats-v-dogs/testing/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-boulder",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1.0/255.) #rescale\n",
    "train_data = train_datagen.flow_from_directory(train,\n",
    "                                              batch_size = 20,\n",
    "                                              class_mode = \"binary\",\n",
    "                                              target_size = (150,150)) # resize\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255.) # rescale\n",
    "validaton_data = validation_datagen.flow_from_directory(validation,\n",
    "                                                       batch_size = 20,\n",
    "                                                       class_mode = \"binary\",\n",
    "                                                       target_size = (150,150)) # resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-version",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),padding=\"same\",input_shape = (150,150,3)))\n",
    "model.add(layers.ReLU()) \n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(32,(3,3),padding=\"same\"))\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3),padding=\"same\"))\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "model.compile(loss= \"binary_crossentropy\",\n",
    "             optimizer =RMSprop(lr=0.001),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-albania",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_data,\n",
    "                              epochs = 30, \n",
    "                              steps_per_epoch = 21147//20, # images = batch_size * steps\n",
    "                              validation_data = validaton_data,\n",
    "                              validation_steps=2342//20) # images = batch_size * steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-register",
   "metadata": {},
   "source": [
    "As we see our base model is overfitting.<br>\n",
    "There are three cause of overfitting:- <br>\n",
    "1. Lack of data.\n",
    "2. Unbalanced data (but we already solve this cause).\n",
    "3. Our model is not much complex for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-harvard",
   "metadata": {},
   "source": [
    "Solution:-<br> To overcome overfitting first we use data augmentation and then train our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-dietary",
   "metadata": {},
   "source": [
    "# new model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-casting",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(train,\n",
    "                                              batch_size = 150,\n",
    "                                              class_mode = \"binary\",\n",
    "                                              target_size = (150,150)) \n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255.) # rescale\n",
    "validaton_data = validation_datagen.flow_from_directory(validation,\n",
    "                                                       batch_size = 150,\n",
    "                                                       class_mode = \"binary\",\n",
    "                                                       target_size = (150,150)) # resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-local",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),padding=\"same\",input_shape = (150,150,3)))\n",
    "model.add(layers.ReLU()) \n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "  \n",
    "model.add(layers.Conv2D(64,(3,3),padding=\"same\"))\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3),padding=\"same\"))\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3),padding=\"same\"))\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-democracy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "model.compile(loss= \"binary_crossentropy\",\n",
    "             optimizer =RMSprop(lr=0.0001),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_data,\n",
    "                  epochs = 30, \n",
    "                 steps_per_epoch = 21147//150, # images = batch_size * steps\n",
    "                validation_data = validaton_data,\n",
    "                validation_steps=2342//150) # images = batch_size * steps )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-focus",
   "metadata": {},
   "source": [
    "After increasing image data by using Data Augmentation, our model predict well good but little underfitting.<br>\n",
    "Now we use regularization technique (Dropout) with 50% 0f neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-least",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "separate-yorkshire",
   "metadata": {},
   "source": [
    "# New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),padding=\"same\",input_shape = (150,150,3)))\n",
    "model.add(layers.ReLU()) \n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3),padding=\"same\"))\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3),padding=\"same\"))\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3),padding=\"same\"))\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(layers.Dense(512))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(train,\n",
    "                                              batch_size = 150,\n",
    "                                              class_mode = \"binary\",\n",
    "                                              target_size = (150,150)) \n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255.) # rescale\n",
    "validaton_data = validation_datagen.flow_from_directory(validation,\n",
    "                                                       batch_size = 150,\n",
    "                                                       class_mode = \"binary\",\n",
    "                                                       target_size = (150,150)) # resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "model.compile(loss= \"binary_crossentropy\",\n",
    "             optimizer =RMSprop(lr=0.0001),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_data,\n",
    "                  epochs = 30, \n",
    "                 steps_per_epoch = 21147//150, # (images = batch_size * steps)\n",
    "                validation_data = validaton_data,  \n",
    "                validation_steps=2342//150) # (images = batch_size * steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cat_dog.h5\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-edward",
   "metadata": {},
   "source": [
    "Little bit good but i think it need more Dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-multiple",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "imgplot = cv2.imread(\"test1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('cat_dog.h5')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "img = cv2.imread('test1.jpg') #dog\n",
    "img = cv2.resize(img,(150,150))\n",
    "img = img.astype('float32')\n",
    "img = np.reshape(img,[1,150,150,3])\n",
    "\n",
    "classes = model.predict_classes(img)\n",
    "\n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-northwest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "image_path=\"test/cat.jpg\"\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "result=model.predict_classes(img)\n",
    "plt.title((result[0][0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "image_path=\"dog.jpg\"\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "result=model.predict_classes(img)\n",
    "plt.title((result[0][0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "image_path=\"test/dog.jpg\"\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "result=model.predict_classes(img)\n",
    "plt.title((result[0][0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-lancaster",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
